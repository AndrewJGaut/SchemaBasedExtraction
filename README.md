# SchemaBasedExtraction


Directory Structure
* DBPedia contains code for obtaining structured data from DBPedia and creating a dataset from that
* Models contains relation extraction models we will be testing
* Wikipedia data contains code for scraping articles from Wikipedia (which we use to obtain sentences that we distantly supervise using KB data)
* Tests are informal scripts we use to test functions before adding them to our actual code base.
